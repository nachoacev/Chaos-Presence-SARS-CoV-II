{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LO QUE FALTA ES:\n",
    "#1. cambiar los metodos MLE_Daily_Cases y Positividad, agregar muertes y ojala camas.\n",
    "#2. subirlo al github\n",
    "#3. Hacer un latex o algo explicando los metodos utilizados, si es posible alguna que otra cosa con demostración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui se contruyen los algoritmos utilizados para la estimación de Máximos exponentes de Lyapunov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para el tiempo de retardo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculo de la información mutua."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mi(x, y, bins=64):\n",
    "    \"\"\"Calculate the mutual information between two random variables.\n",
    "    Calculates mutual information, I = S(x) + S(y) - S(x,y), between two\n",
    "    random variables x and y, where S(x) is the Shannon entropy.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array\n",
    "        First random variable.\n",
    "    y : array\n",
    "        Second random variable.\n",
    "    bins : int\n",
    "        Number of bins to use while creating the histogram.\n",
    "    Returns\n",
    "    -------\n",
    "    i : float\n",
    "        Mutual information.\n",
    "    \"\"\"\n",
    "    p_x = np.histogram(x, bins)[0]\n",
    "    p_y = np.histogram(y, bins)[0]\n",
    "    p_xy = np.histogram2d(x, y, bins)[0].flatten()\n",
    "\n",
    "    # Convert frequencies into probabilities.  Also, in the limit\n",
    "    # p -> 0, p*log(p) is 0.  We need to take out those.\n",
    "    p_x = p_x[p_x > 0] / np.sum(p_x)\n",
    "    p_y = p_y[p_y > 0] / np.sum(p_y)\n",
    "    p_xy = p_xy[p_xy > 0] / np.sum(p_xy)\n",
    "\n",
    "    # Calculate the corresponding Shannon entropies.\n",
    "    h_x = np.sum(p_x * np.log2(p_x))\n",
    "    h_y = np.sum(p_y * np.log2(p_y))\n",
    "    h_xy = np.sum(p_xy * np.log2(p_xy))\n",
    "\n",
    "    return h_xy - h_x - h_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función de autocorrelación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para la dimensión de inmersión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False nearest neighbor algorithm ESTE IMPLEMENTEMOS\n",
    "# ver si funciona Average nearest neighbor, no parece muy convincente DESPUES VEMOS SI ESTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El algoritmo de nearest false neighbors mediante un criterio identifica los falsos vecinos la tratar de describir la\n",
    "#serie en un espacio de cierta dimensión, la dimensión a utilizar será una vez que los falsos vecinos alcance el menor número\n",
    "#posible.\n",
    "#Kennel et al s tests?\n",
    "from nolitsa import utils\n",
    "import numpy as np\n",
    "def _fnn(d, x, tau=1, R=10.0, A=2.0, metric='euclidean', window=10,\n",
    "         maxnum=None):\n",
    "    \"\"\"Return fraction of false nearest neighbors for a single d.\n",
    "    Returns the fraction of false nearest neighbors for a single d.\n",
    "    This function is meant to be called from the main fnn() function.\n",
    "    See the docstring of fnn() for more.\n",
    "    \"\"\"\n",
    "    # We need to reduce the number of points in dimension d by tau\n",
    "    # so that after reconstruction, there'll be equal number of points\n",
    "    # at both dimension d as well as dimension d + 1.\n",
    "    y1 = utils.reconstruct(x[:-tau], d, tau)\n",
    "    y2 = utils.reconstruct(x, d + 1, tau)\n",
    "\n",
    "    # Find near neighbors in dimension d.\n",
    "    index, dist = utils.neighbors(y1, metric=metric, window=window,\n",
    "                                  maxnum=maxnum)\n",
    "\n",
    "    # Find all potential false neighbors using Kennel et al.'s tests.\n",
    "    f1 = np.abs(y2[:, -1] - y2[index, -1]) / dist > R\n",
    "    f2 = utils.dist(y2, y2[index], metric=metric) / np.std(x) > A\n",
    "    f3 = f1 | f2\n",
    "\n",
    "    return np.mean(f1), np.mean(f2), np.mean(f3)\n",
    "\n",
    "def fnn(x, dim=[1], tau=1, R=10.0, A=2.0, metric='euclidean', window=10,\n",
    "        maxnum=None, parallel=True):\n",
    "    \"\"\"Compute the fraction of false nearest neighbors.\n",
    "    Implements the false nearest neighbors (FNN) method described by\n",
    "    Kennel et al. (1992) to calculate the minimum embedding dimension\n",
    "    required to embed a scalar time series.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array\n",
    "        1-D real input array containing the time series.\n",
    "    dim : int array (default = [1])\n",
    "        Embedding dimensions for which the fraction of false nearest\n",
    "        neighbors should be computed.\n",
    "    tau : int, optional (default = 1)\n",
    "        Time delay.\n",
    "    R : float, optional (default = 10.0)\n",
    "        Tolerance parameter for FNN Test I.\n",
    "    A : float, optional (default = 2.0)\n",
    "        Tolerance parameter for FNN Test II.\n",
    "    metric : string, optional (default = 'euclidean')\n",
    "        Metric to use for distance computation.  Must be one of\n",
    "        \"cityblock\" (aka the Manhattan metric), \"chebyshev\" (aka the\n",
    "        maximum norm metric), or \"euclidean\".  Also see Notes.\n",
    "    window : int, optional (default = 10)\n",
    "        Minimum temporal separation (Theiler window) that should exist\n",
    "        between near neighbors.\n",
    "    maxnum : int, optional (default = None (optimum))\n",
    "        Maximum number of near neighbors that should be found for each\n",
    "        point.  In rare cases, when there are no neighbors that are at a\n",
    "        nonzero distance, this will have to be increased (i.e., beyond\n",
    "        2 * window + 3).\n",
    "    parallel : bool, optional (default = True)\n",
    "        Calculate the fraction of false nearest neighbors for each d\n",
    "        in parallel.\n",
    "    Returns\n",
    "    -------\n",
    "    f1 : array\n",
    "        Fraction of neighbors classified as false by Test I.\n",
    "    f2 : array\n",
    "        Fraction of neighbors classified as false by Test II.\n",
    "    f3 : array\n",
    "        Fraction of neighbors classified as false by either Test I\n",
    "        or Test II.\n",
    "    Notes\n",
    "    -----\n",
    "    The FNN fraction is metric depended for noisy time series.  In\n",
    "    particular, the second FNN test, which measures the boundedness of\n",
    "    the reconstructed attractor depends heavily on the metric used.\n",
    "    E.g., if the Chebyshev metric is used, the near-neighbor distances\n",
    "    in the reconstructed attractor are always bounded and therefore the\n",
    "    reported FNN fraction becomes a nonzero constant (approximately)\n",
    "    instead of increasing with the embedding dimension.\n",
    "    \"\"\"\n",
    "    f_1=np.zeros(len(dim))\n",
    "    f_2=np.zeros(len(dim))\n",
    "    f_3=np.zeros(len(dim))\n",
    "    for i in range(len(dim)):\n",
    "        f_1[i], f_2[i], f_3[i]=_fnn(dim[i], x, tau, R, A, metric, window=10,maxnum=None)\n",
    "    return f_1,f_2,f_3\n",
    "\n",
    "\n",
    "#Esta ultima función entrega el % de falsos vecinos bajo un Test I, Test II y el Test III que es haber pasado los dos anteriores\n",
    "# (El test III es falso si lo es para alguno de los tests anteriores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos la data.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.read_excel (r'C:\\Users\\javie\\Desktop\\Modelamiento\\Datos\\de maass\\covid19 CHILE REGIONES-CURSOMM.xlsx', sheet_name='Casos')\n",
    "df = pd.DataFrame(data, columns= ['fecha','RM','Maule','Valparaiso'])\n",
    "#RM\n",
    "timeseries=np.array(df.RM)[:-147]\n",
    "X=timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d203de1c31b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Ejemplo de como usarlo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnolitsa\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdimension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cityblock'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#Ejemplo de como usarlo\n",
    "from nolitsa import dimension\n",
    "dim = np.arange(1, 10 + 1)\n",
    "f1, f2, f3 = fnn(X, tau=4, dim=dim, window=10, metric='cityblock')\n",
    "\n",
    "plt.title(r'FNN for Henon map')\n",
    "plt.xlabel(r'Embedding dimension $d$')\n",
    "plt.ylabel(r'FNN (%)')\n",
    "plt.plot(dim, 100 * f1, 'bo--', label=r'Test I')\n",
    "\"\"\"plt.plot(dim, 100 * f2, 'g^--', label=r'Test II')\n",
    "plt.plot(dim, 100 * f3, 'rs-', label=r'Test I + II')\"\"\"\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimación de los exponentes de Lyapunov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dos algoritmos posibles, Rosenstein et al. 1993, y el otro es el algoritmo de Wolf et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mle(y, maxt=500, window=10, metric='euclidean', maxnum=None):\n",
    "    \"\"\"Estimate the maximum Lyapunov exponent.\n",
    "    Estimates the maximum Lyapunov exponent (MLE) from a\n",
    "    multi-dimensional series using the algorithm described by\n",
    "    Rosenstein et al. (1993).\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : ndarray\n",
    "        Multi-dimensional real input array containing points in the\n",
    "        phase space.\n",
    "    maxt : int, optional (default = 500)\n",
    "        Maximum time (iterations) up to which the average divergence\n",
    "        should be computed.\n",
    "    window : int, optional (default = 10)\n",
    "        Minimum temporal separation (Theiler window) that should exist\n",
    "        between near neighbors (see Notes).\n",
    "    maxnum : int, optional (default = None (optimum))\n",
    "        Maximum number of near neighbors that should be found for each\n",
    "        point.  In rare cases, when there are no neighbors that are at a\n",
    "        nonzero distance, this will have to be increased (i.e., beyond\n",
    "        2 * window + 3).\n",
    "    Returns\n",
    "    -------\n",
    "    d : array\n",
    "        Average divergence for each time up to maxt.\n",
    "    Notes\n",
    "    -----\n",
    "    This function does not directly estimate the MLE.  The MLE should be\n",
    "    estimated by linearly fitting the average divergence (i.e., the\n",
    "    average of the logarithms of near-neighbor distances) with time.\n",
    "    It is also important to choose an appropriate Theiler window so that\n",
    "    the near neighbors do not lie on the same trajectory, in which case\n",
    "    the estimated MLE will always be close to zero.\n",
    "    \"\"\"\n",
    "    index, dist = utils.neighbors(y, metric=metric, window=window,\n",
    "                                  maxnum=maxnum)\n",
    "    m = len(y)\n",
    "    maxt = min(m - window - 1, maxt)\n",
    "\n",
    "    d = np.empty(maxt)\n",
    "    d[0] = np.mean(np.log(dist))\n",
    "\n",
    "    for t in range(1, maxt):\n",
    "        t1 = np.arange(t, m)\n",
    "        t2 = index[:-t] + t\n",
    "\n",
    "        # Sometimes the nearest point would be farther than (m - maxt)\n",
    "        # in time.  Such trajectories needs to be omitted.\n",
    "        valid = t2 < m\n",
    "        t1, t2 = t1[valid], t2[valid]\n",
    "\n",
    "        d[t] = np.mean(np.log(utils.dist(y[t1], y[t2], metric=metric)))\n",
    "\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo de como usarlo para obtener la \"divergencia aparentemente\"\n",
    "dim=[3]\n",
    "yy = [utils.reconstruct(x, dim=d, tau=5) for d in dim]\n",
    "Div=mle(yy[0])\n",
    "plt.plot(Div[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisar que en efecto se obtiene el exponente de lyapunov mediante un linear fitting ESTO ES MUY IMPORTANTE.\n",
    "# https://arxiv.org/ftp/arxiv/papers/1508/1508.00996.pdf \n",
    "# Aqui dice que hay que sacar la slope y porque."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
